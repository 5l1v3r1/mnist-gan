{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GAN) example in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 200\n",
    "d_steps = 1  # k >= 1\n",
    "g_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n"
     ]
    }
   ],
   "source": [
    "preprocess, d_input_func = lambda data: data, lambda x: x)\n",
    "preprocess, d_input_func = lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: D: 0.6981781125068665/0.755477786064148 G: 0.6416189074516296 (Real: [4.0547098523378375, 1.2314252959340828], Fake: [-0.28511309772729876, 0.0099985404669034675]) \n",
      "200: D: 0.0009525781497359276/0.451774924993515 G: 1.0012849569320679 (Real: [3.6725147613883018, 1.3844103867078239], Fake: [0.14209336966276168, 0.063836321614812092]) \n",
      "400: D: 0.006096851080656052/0.33512821793556213 G: 1.2866592407226562 (Real: [4.0221354687213902, 1.2193185105708324], Fake: [0.080465802438557152, 0.11968505218068264]) \n",
      "600: D: 0.0010952985612675548/0.3185677230358124 G: 1.268117070198059 (Real: [4.0592756074666978, 1.307170498415837], Fake: [-0.045618432685732839, 0.26553063354745349]) \n",
      "800: D: 0.04345858842134476/0.030353741720318794 G: 3.019766092300415 (Real: [4.1049610841274262, 1.0628556763952564], Fake: [0.87872730329632764, 0.41226892261950321]) \n",
      "1000: D: 0.013587034307420254/0.14907453954219818 G: 2.6867165565490723 (Real: [4.2136442089080814, 1.1570395098039838], Fake: [2.0033200972899796, 0.99912447942535842]) \n",
      "1200: D: 0.26014602184295654/1.2306445837020874 G: 0.9164144992828369 (Real: [3.7692616787552833, 1.2555046869993467], Fake: [3.3695913672447206, 1.3616765124072585]) \n",
      "1400: D: 1.3704150915145874/1.2041770219802856 G: 0.41711941361427307 (Real: [4.0178333473205567, 1.2598850555457008], Fake: [4.1272431612014771, 1.4290207003457156]) \n",
      "1600: D: 0.9988407492637634/0.8900978565216064 G: 0.7175669074058533 (Real: [4.1554326578974727, 1.2331330018932329], Fake: [5.0930861186981202, 1.3498180413681351]) \n",
      "1800: D: 1.1063861846923828/0.37991559505462646 G: 0.8718706965446472 (Real: [4.0264887225627897, 1.1153364076810606], Fake: [5.1192939138412479, 1.4687230402198526]) \n",
      "2000: D: 0.5180148482322693/0.2915368676185608 G: 1.2148009538650513 (Real: [3.8412655794620516, 1.2473856953517874], Fake: [5.4097595047950744, 1.1813578961820042]) \n",
      "2200: D: 0.5794115662574768/0.4281436502933502 G: 0.7104617953300476 (Real: [3.8615920460224151, 1.2014098164750189], Fake: [5.007050087451935, 1.291028168314061]) \n",
      "2400: D: 0.6754503846168518/0.9117527008056641 G: 0.626032292842865 (Real: [4.1977357304096223, 1.1168631030702121], Fake: [4.2829983186721803, 1.0902063329299247]) \n",
      "2600: D: 0.5336487889289856/0.7187370657920837 G: 0.6623055934906006 (Real: [3.985908428430557, 1.1685680538594634], Fake: [3.4917351800203322, 1.1934685644553211]) \n",
      "2800: D: 0.631920337677002/0.6601160168647766 G: 0.7121346592903137 (Real: [4.1665437805652621, 1.2939242967441429], Fake: [3.2326888877153395, 1.0553961446660716]) \n",
      "3000: D: 0.5568937659263611/0.8288511037826538 G: 0.7279390096664429 (Real: [4.0033340966701507, 1.2689963591231339], Fake: [3.7510849571228029, 1.1127082162456152]) \n",
      "3200: D: 0.48467978835105896/1.1451683044433594 G: 0.8170914649963379 (Real: [4.0985775578022006, 1.256734938331783], Fake: [4.5304417073726651, 1.0889489593040766]) \n",
      "3400: D: 0.5817161202430725/0.3133200407028198 G: 0.8238034248352051 (Real: [3.9938339686393736, 1.1962428473093012], Fake: [4.3491354227066044, 1.5109614338837574]) \n",
      "3600: D: 0.5476183891296387/0.5828269720077515 G: 0.9697020649909973 (Real: [4.2087905502319334, 1.3958686883788942], Fake: [4.5349489510059353, 1.0993154380817494]) \n",
      "3800: D: 0.9443452954292297/0.7130414247512817 G: 0.4689997136592865 (Real: [3.910376297235489, 1.3756126942711111], Fake: [4.1969195824861529, 1.2120188022592615]) \n",
      "4000: D: 0.7702817916870117/0.8332642316818237 G: 0.6978752017021179 (Real: [3.9940959000587464, 1.1701366894096226], Fake: [3.5564089059829711, 1.2022687698468535]) \n",
      "4200: D: 0.3699551224708557/0.72049480676651 G: 0.7038640975952148 (Real: [3.8564848829805851, 1.3763543264672471], Fake: [3.7834001386165621, 1.062583038990204]) \n",
      "4400: D: 0.640962541103363/0.9035835266113281 G: 0.7644174695014954 (Real: [3.8269163519144058, 1.127205296337366], Fake: [4.3863579642772672, 1.2290632839740399]) \n",
      "4600: D: 0.998306155204773/0.6405141949653625 G: 0.6207255721092224 (Real: [3.8795809280872344, 1.3693767289608441], Fake: [4.5935368895530697, 1.2345375344879372]) \n",
      "4800: D: 0.41278672218322754/0.7170194983482361 G: 0.658841609954834 (Real: [4.0196681165695187, 1.2244324180576174], Fake: [4.0469304800033568, 1.3372580721776233]) \n",
      "5000: D: 0.595579981803894/0.7189428806304932 G: 0.6798157691955566 (Real: [3.9122239494323732, 1.25753447026916], Fake: [3.6352568709850313, 1.1750079067373294]) \n",
      "5200: D: 0.7013214230537415/0.7056421041488647 G: 0.8033926486968994 (Real: [4.0835421276092525, 1.2850297487739133], Fake: [3.7180246472358705, 1.2990032996523146]) \n",
      "5400: D: 0.6638368368148804/0.6682047843933105 G: 0.5483229756355286 (Real: [3.8937839278578759, 1.2232741114043668], Fake: [4.1226143682003018, 1.2704938786770159]) \n",
      "5600: D: 0.9373252987861633/0.5823751091957092 G: 0.8381944298744202 (Real: [3.9576256120204927, 1.2444113498120755], Fake: [4.2222929883003237, 1.3501923265730782]) \n",
      "5800: D: 0.6646407842636108/0.8952229022979736 G: 0.8113473653793335 (Real: [3.9603424465656278, 1.13026424601923], Fake: [3.896245838403702, 1.1283042030362542]) \n",
      "6000: D: 0.7491537928581238/0.5464217066764832 G: 0.902719259262085 (Real: [4.1127457404136658, 1.2635967071400345], Fake: [3.9033974957466127, 1.2970433630051399]) \n",
      "6200: D: 0.6365458369255066/0.6970597505569458 G: 0.6850250363349915 (Real: [4.1569416761398319, 1.2207253343887134], Fake: [4.0808937650918962, 1.3564923773246305]) \n",
      "6400: D: 0.7170283198356628/0.6442924737930298 G: 0.7631269097328186 (Real: [4.0878446125984196, 1.1351125798230126], Fake: [3.7310729992389677, 1.2305545467014369]) \n",
      "6600: D: 0.7481356263160706/0.5109004378318787 G: 0.8589295744895935 (Real: [3.7891454535722731, 1.4188303706802474], Fake: [3.4969567167758941, 1.3458215813133594]) \n",
      "6800: D: 0.5371662378311157/0.7403262853622437 G: 0.7903671860694885 (Real: [4.1808029103279116, 1.1954699117892678], Fake: [4.3643467509746552, 1.2155954099509991]) \n",
      "7000: D: 0.6516798734664917/0.7212162017822266 G: 0.5163359045982361 (Real: [4.0229838144779206, 1.1834592113918216], Fake: [3.9145914053916933, 1.2261961809719537]) \n",
      "7200: D: 0.6961439251899719/0.8669219613075256 G: 0.589288592338562 (Real: [4.0884553366899494, 1.339207411414276], Fake: [3.9493397212028505, 1.1434010359289704]) \n",
      "7400: D: 0.8337121605873108/0.6266261339187622 G: 0.649580717086792 (Real: [4.0120970511436465, 1.303705241735682], Fake: [4.249154260158539, 1.2276155771399773]) \n",
      "7600: D: 0.6458337306976318/0.7753549218177795 G: 0.6792482137680054 (Real: [3.9746094971895216, 1.3058229457487482], Fake: [3.9483413314819336, 1.1893499166030728]) \n",
      "7800: D: 0.6327599883079529/0.6692772507667542 G: 0.8194636702537537 (Real: [4.0230972778797147, 1.2714899854706398], Fake: [4.0388141405582427, 1.3905271823036074]) \n",
      "8000: D: 0.6509706974029541/0.49451759457588196 G: 0.7367027401924133 (Real: [4.1190577900409702, 1.3546043881647478], Fake: [3.8440411317348482, 1.2138900113012707]) \n",
      "8200: D: 0.8003093600273132/0.4821816682815552 G: 0.7475970983505249 (Real: [3.8776001781225204, 1.1612798443039902], Fake: [3.9522997522354126, 1.4159959429946347]) \n",
      "8400: D: 0.6264271140098572/0.924452006816864 G: 0.7230342626571655 (Real: [4.0179489690065386, 1.2888577332733975], Fake: [4.1176215457916259, 1.2803577783269593]) \n",
      "8600: D: 0.6153157949447632/0.6203101873397827 G: 0.6640756726264954 (Real: [3.9537308239936828, 1.1532053057687044], Fake: [3.9649229633808134, 1.2202991371525098]) \n",
      "8800: D: 0.6031652688980103/0.6398550271987915 G: 0.5219185948371887 (Real: [3.9517314726114274, 1.3374998198787176], Fake: [4.0628678059577945, 1.2926276166030342]) \n",
      "9000: D: 0.5543325543403625/0.6126587986946106 G: 0.6273368000984192 (Real: [3.8935850772261618, 1.1547076000050926], Fake: [3.8295843988656997, 1.2577486827423883]) \n",
      "9200: D: 0.835148274898529/0.5912653207778931 G: 0.8090696930885315 (Real: [4.1244084966182708, 1.1688105494178171], Fake: [4.2080373394489285, 1.1175992149233371]) \n",
      "9400: D: 1.0473147630691528/0.9248344302177429 G: 0.7463006377220154 (Real: [4.0849868053197858, 1.0944513853861986], Fake: [3.626206437945366, 1.4078507239748879]) \n",
      "9600: D: 0.8838926553726196/0.6930772662162781 G: 0.604887843132019 (Real: [3.9198265784978865, 1.2538147969053774], Fake: [4.0188892459869381, 1.238301473852081]) \n",
      "9800: D: 0.7590035796165466/0.5234367251396179 G: 0.6191973686218262 (Real: [3.8366183161735536, 1.1457423861530385], Fake: [4.0063357943296429, 1.4161810649631676]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: D: 0.5003601312637329/1.172639012336731 G: 0.37165704369544983 (Real: [3.9852352273464202, 1.1590077681765674], Fake: [4.0687204885482791, 1.229554758161314]) \n",
      "10200: D: 0.9755654335021973/0.7196236252784729 G: 0.8616246581077576 (Real: [4.0175358653068542, 1.1447951729589665], Fake: [3.9511641836166382, 1.3466961627958391]) \n",
      "10400: D: 0.37218981981277466/0.7939143180847168 G: 0.7537536025047302 (Real: [3.8593139111995698, 1.2168616469643259], Fake: [3.9173891496658326, 1.1199848083709121]) \n",
      "10600: D: 0.8577403426170349/0.6049784421920776 G: 0.618677020072937 (Real: [4.0312767395377156, 1.2784476278844978], Fake: [4.3731682640314098, 1.2742238975508162]) \n",
      "10800: D: 0.6766371130943298/0.6346055865287781 G: 0.7929967641830444 (Real: [3.855501775741577, 1.3379375899211765], Fake: [4.2419640529155735, 0.97599873996567366]) \n",
      "11000: D: 0.8232480883598328/0.685746967792511 G: 0.8170490264892578 (Real: [3.9466886144876479, 1.222878085185122], Fake: [3.9818111205101014, 1.1498052838073065]) \n",
      "11200: D: 0.563460648059845/0.6209357380867004 G: 1.0394456386566162 (Real: [3.7912179589271546, 1.1230817258054329], Fake: [4.0399287688732146, 1.4158488927998452]) \n",
      "11400: D: 0.6996391415596008/0.6669005751609802 G: 0.6860337853431702 (Real: [4.0876633870601653, 1.2723395095336503], Fake: [3.6639637809991839, 1.3326269613825834]) \n",
      "11600: D: 0.39255189895629883/0.5035567879676819 G: 0.4350244104862213 (Real: [3.8974782896041869, 1.2323248413904837], Fake: [4.1874828988313677, 1.0407541796329933]) \n",
      "11800: D: 0.6904599070549011/0.5007697939872742 G: 0.7291366457939148 (Real: [4.0481549131870267, 1.0917576406411613], Fake: [4.0144521576166152, 1.2955304537902128]) \n",
      "12000: D: 0.3076518774032593/0.5417710542678833 G: 1.1997848749160767 (Real: [3.9645177376270295, 1.1246082429985589], Fake: [3.9979531341791152, 1.2194114701522454]) \n",
      "12200: D: 0.7448109984397888/0.37558141350746155 G: 0.5157603025436401 (Real: [4.1582251024246215, 1.16402946590984], Fake: [4.1967151939868925, 1.1148737799183275]) \n",
      "12400: D: 0.8221718668937683/0.31067606806755066 G: 0.9736263155937195 (Real: [4.0957916903495786, 1.2982567522021953], Fake: [4.1410612887144085, 1.1096375285791418]) \n",
      "12600: D: 1.036821722984314/0.38898882269859314 G: 0.698853611946106 (Real: [4.04110537648201, 1.1711295547569982], Fake: [3.7736608856916427, 1.1610867200973851]) \n",
      "12800: D: 0.6786448359489441/0.7250014543533325 G: 1.0086455345153809 (Real: [3.9109959244728087, 1.1606436538599143], Fake: [3.8460614919662475, 1.3840136791296935]) \n",
      "13000: D: 1.056308388710022/0.4202786982059479 G: 1.3956778049468994 (Real: [3.7806523859500887, 1.1440824976125441], Fake: [4.3689535796642307, 1.1959580617650336]) \n",
      "13200: D: 0.7012086510658264/0.7705835103988647 G: 0.44321078062057495 (Real: [4.0306413841247561, 1.1066055162815029], Fake: [3.9822315537929533, 1.2580177353326512]) \n",
      "13400: D: 0.8585227131843567/0.7858675122261047 G: 0.9516029953956604 (Real: [4.0066308867931362, 1.1200356604726069], Fake: [4.0461134010553357, 1.0540407207737692]) \n",
      "13600: D: 0.8373904228210449/0.9775344729423523 G: 0.9153610467910767 (Real: [4.2091747713088985, 1.2179528591138487], Fake: [4.3927519500255583, 1.2606527339523077]) \n",
      "13800: D: 0.2639252543449402/1.224509596824646 G: 0.8364470601081848 (Real: [3.7181758844852446, 1.2559256129140197], Fake: [4.0430624151229857, 1.3159075396808826]) \n",
      "14000: D: 0.7433450818061829/0.5650330781936646 G: 0.719254732131958 (Real: [3.7131655478477477, 1.2036729230967202], Fake: [4.2157623422145845, 1.1961761373770199]) \n",
      "14200: D: 0.16629570722579956/0.8050838112831116 G: 0.992055356502533 (Real: [4.1797515189647676, 1.2951823357945076], Fake: [3.955135684609413, 1.1477959185307116]) \n",
      "14400: D: 0.21863315999507904/0.5282235741615295 G: 0.9085699915885925 (Real: [3.8193542671203615, 1.0467530362290201], Fake: [4.0290694069862365, 1.1742380564335992]) \n",
      "14600: D: 0.37205377221107483/0.7282584309577942 G: 1.0180442333221436 (Real: [4.175414697825909, 1.3104354667850531], Fake: [4.163135612607002, 1.2081968138556056]) \n",
      "14800: D: 0.5337783694267273/0.6170499920845032 G: 0.6783291697502136 (Real: [3.9507653498649598, 1.295909324402476], Fake: [4.2262771272659299, 1.3055855189293795]) \n",
      "15000: D: 0.5750207901000977/0.4119006395339966 G: 0.6975409984588623 (Real: [4.0217372524738311, 1.0842889000233396], Fake: [4.2797806227207182, 1.1734321303370923]) \n",
      "15200: D: 0.3291981518268585/0.5425728559494019 G: 1.4020222425460815 (Real: [3.8020575970411299, 1.1217031125458523], Fake: [3.902181589603424, 1.3191858678279247]) \n",
      "15400: D: 0.31507691740989685/0.3164476752281189 G: 0.6146459579467773 (Real: [4.0661567043699325, 1.1589692247838632], Fake: [3.8417615354061128, 1.2636396665759557]) \n",
      "15600: D: 0.5922509431838989/0.56312096118927 G: 1.2957637310028076 (Real: [3.9544368283450604, 1.2781210610901432], Fake: [4.3426334798336033, 1.1469334118521524]) \n",
      "15800: D: 0.5483401417732239/0.55776447057724 G: 0.9487125873565674 (Real: [4.0152727198600768, 1.3040064764863555], Fake: [4.0285506385564807, 1.2558680884044169]) \n",
      "16000: D: 0.5780795216560364/0.39396053552627563 G: 0.8847472667694092 (Real: [4.0953719091415408, 1.1494618638312695], Fake: [4.0340022158622739, 1.2857246467703667]) \n",
      "16200: D: 1.1155225038528442/0.7532171010971069 G: 0.812130868434906 (Real: [4.0074798470735553, 1.1178691603408479], Fake: [4.2963119328022001, 1.1280809488830159]) \n",
      "16400: D: 0.4558384120464325/0.5921415686607361 G: 1.2360146045684814 (Real: [3.7733531919121743, 1.2602896716577192], Fake: [4.0101498115062713, 1.218810261153747]) \n",
      "16600: D: 0.37048715353012085/0.4807932674884796 G: 0.9080148339271545 (Real: [4.0542317402362826, 1.1615324056842926], Fake: [3.8442574006319048, 1.4008934608666077]) \n",
      "16800: D: 0.06087499111890793/0.22863876819610596 G: 0.3699953556060791 (Real: [4.1171001218259331, 1.3652385874168314], Fake: [4.2243165862560268, 1.1520430671262702]) \n",
      "17000: D: 0.1433444619178772/0.20313361287117004 G: 1.4813364744186401 (Real: [4.1058851206302647, 1.1313478825366674], Fake: [4.1736470222473141, 1.3443592155128297]) \n",
      "17200: D: 0.43815723061561584/0.20317699015140533 G: 0.9036160707473755 (Real: [3.9989314579963686, 1.1345977714511239], Fake: [4.3445626330375671, 1.1315496241108556]) \n",
      "17400: D: 0.2885872721672058/0.7090041637420654 G: 0.7576625347137451 (Real: [4.0186593127250667, 1.3146244109987637], Fake: [4.1112305366992947, 1.1896546977879661]) \n",
      "17600: D: 0.5312575697898865/0.6401225924491882 G: 0.9301311373710632 (Real: [4.1745066815614704, 1.3108788255362516], Fake: [3.82349644780159, 1.3075685000263544]) \n",
      "17800: D: 0.06251509487628937/0.6029041409492493 G: 1.726945400238037 (Real: [4.1440348938107494, 1.4619272038205899], Fake: [3.9136713361740112, 1.3016818040361327]) \n",
      "18000: D: 0.2376062273979187/0.4705279469490051 G: 1.312968373298645 (Real: [3.8987248182296752, 1.0676494563126038], Fake: [4.0339117836952205, 1.2548490876812051]) \n",
      "18200: D: 0.33785638213157654/0.5714045763015747 G: 0.2612592875957489 (Real: [3.9782396757602694, 1.2152236960610447], Fake: [4.0174305260181429, 1.2491519829888593]) \n",
      "18400: D: 0.28877055644989014/0.4862027168273926 G: 1.1382895708084106 (Real: [3.7846967554092408, 1.0211552029311044], Fake: [4.0803277492523193, 1.117407650968762]) \n",
      "18600: D: 0.11603160202503204/0.43241047859191895 G: 1.8393446207046509 (Real: [3.9625557583570479, 1.2774918223921423], Fake: [3.9164339637756349, 1.1904871575265425]) \n",
      "18800: D: 0.38012731075286865/0.17100872099399567 G: 0.36480608582496643 (Real: [4.0352377939224242, 1.2778228856054497], Fake: [3.8739834809303284, 1.3622632415409079]) \n",
      "19000: D: 0.2755483090877533/0.2994542121887207 G: 1.1943812370300293 (Real: [3.968048105239868, 1.0779664899968802], Fake: [4.018391480445862, 1.2499218618942787]) \n",
      "19200: D: 0.13309143483638763/0.48323845863342285 G: 2.3445956707000732 (Real: [3.844454561471939, 1.1648763136172215], Fake: [4.1210408961772922, 1.3029986923620411]) \n",
      "19400: D: 1.3231490850448608/0.9264366030693054 G: 1.629192590713501 (Real: [4.1609305655956268, 1.1018743429513564], Fake: [3.8447790098190309, 1.3633569571137794]) \n",
      "19600: D: 0.6662821173667908/0.22698549926280975 G: 1.5883437395095825 (Real: [4.0285845792293546, 1.0774676562370786], Fake: [4.1182074272632603, 1.2035375880876666]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19800: D: 0.5665174722671509/0.25150051712989807 G: 1.6446659564971924 (Real: [4.0396297061443329, 1.2025047058152705], Fake: [3.8883231937885285, 1.3786591640294428]) \n",
      "20000: D: 0.12129618227481842/0.1923273652791977 G: 2.1840627193450928 (Real: [4.0129013103246685, 1.3621970283850597], Fake: [4.1223703467845914, 1.3159434614145862]) \n",
      "20200: D: 0.055870864540338516/0.11196769028902054 G: 2.5396525859832764 (Real: [3.9606452202796936, 1.1675076246315217], Fake: [3.8837533509731292, 1.3205521437912644]) \n",
      "20400: D: 0.7079916000366211/0.058159612119197845 G: 1.886824607849121 (Real: [3.9738567399978639, 1.1051662760210235], Fake: [4.0049975240230564, 1.2540673828517888]) \n",
      "20600: D: 0.03515109792351723/0.05685963109135628 G: 1.3269304037094116 (Real: [4.0202750995755192, 1.3124802611963766], Fake: [4.098667097091675, 1.2341350539348426]) \n",
      "20800: D: 0.0010486376704648137/0.575573742389679 G: 1.452439785003662 (Real: [3.905985063314438, 1.2034626258637202], Fake: [4.2762358474731448, 1.1008494291030777]) \n",
      "21000: D: 0.49735143780708313/0.19221548736095428 G: 1.8203424215316772 (Real: [4.2087137281894682, 1.1738524289332541], Fake: [4.2758944666385652, 1.2766553617731287]) \n",
      "21200: D: 0.5304363369941711/0.0955931693315506 G: 1.1762969493865967 (Real: [4.0382603251934048, 1.2485971552570034], Fake: [4.3287949550151827, 1.2989677773608146]) \n",
      "21400: D: 0.06809115409851074/0.6073238849639893 G: 0.5316301584243774 (Real: [4.1128442746400831, 1.3123088616825724], Fake: [4.129463801383972, 1.1749321409945721]) \n",
      "21600: D: 0.16074544191360474/0.18159723281860352 G: 0.9286940097808838 (Real: [3.9635157656669615, 1.2682245912067263], Fake: [4.5999604725837706, 1.2265925129712305]) \n",
      "21800: D: 0.1771143674850464/0.8644119501113892 G: 1.3413417339324951 (Real: [3.9126122474670408, 1.1621640126817681], Fake: [3.9775790238380431, 1.417192531823964]) \n",
      "22000: D: 0.11836080998182297/0.0903497114777565 G: 1.8443855047225952 (Real: [4.1329583108425139, 1.1739308198673188], Fake: [4.5621648025512691, 1.1015785055743956]) \n",
      "22200: D: 0.007327334955334663/0.29392674565315247 G: 1.0534868240356445 (Real: [4.0530501449108121, 1.2637529072618701], Fake: [4.2325528430938721, 1.3290371721601741]) \n",
      "22400: D: 0.08834867179393768/0.31275099515914917 G: 2.3141515254974365 (Real: [3.6593893337249757, 1.1999501577489975], Fake: [4.1795964598655697, 1.1267117917864156]) \n",
      "22600: D: 0.8032696843147278/1.3083720207214355 G: 1.8306400775909424 (Real: [4.0814785492420196, 1.2141662166655016], Fake: [4.4260414814949032, 1.3283749783505581]) \n",
      "22800: D: 0.09124597162008286/0.43457651138305664 G: 1.7353720664978027 (Real: [4.2006561225652694, 1.25184722255993], Fake: [4.530401339530945, 1.2345318909531753]) \n",
      "23000: D: 0.034842707216739655/0.45818009972572327 G: 0.504698634147644 (Real: [3.9424154889583587, 1.1895847251390552], Fake: [4.6967922127246853, 1.4785189839550892]) \n",
      "23200: D: 0.40345704555511475/0.053286317735910416 G: 1.420993447303772 (Real: [4.020952907800674, 1.2361713990884351], Fake: [4.5980158185958864, 1.2424805066628581]) \n",
      "23400: D: 0.1689302921295166/0.18075375258922577 G: 3.0536792278289795 (Real: [4.0874156308174134, 1.3337407732837545], Fake: [4.7248542237281796, 1.2099577180426999]) \n",
      "23600: D: 0.12772034108638763/2.358954906463623 G: 0.6404047608375549 (Real: [3.9723370802402496, 1.2373667228139908], Fake: [4.1829116725921631, 1.2366144280213365]) \n",
      "23800: D: 0.4281384348869324/0.17126913368701935 G: 0.9397834539413452 (Real: [3.9191101813316345, 1.2394737313567938], Fake: [3.7421142363548281, 1.1377068270939525]) \n",
      "24000: D: 0.33850109577178955/0.28177422285079956 G: 0.7347337603569031 (Real: [4.0865796923637392, 1.1280900961879625], Fake: [4.4127504587173458, 1.3330170532973484]) \n",
      "24200: D: 0.625299870967865/0.43082475662231445 G: 2.8297195434570312 (Real: [3.9053164815902708, 1.2607114239558843], Fake: [4.9070168542861943, 1.3413439110519394]) \n",
      "24400: D: 0.0742638036608696/0.039528172463178635 G: 1.9935495853424072 (Real: [4.0195186422020193, 1.2909294385450159], Fake: [5.4197959470748902, 1.1488544510717082]) \n",
      "24600: D: 0.007482978515326977/0.5465632081031799 G: 2.9030420780181885 (Real: [3.9199235260486605, 1.1823470183795866], Fake: [5.5100801181793209, 1.5799169061156502]) \n",
      "24800: D: 0.04984038695693016/0.24571283161640167 G: 0.47930818796157837 (Real: [3.9954350185394287, 1.2305951464122422], Fake: [5.2437990927696232, 1.3338095378924619]) \n",
      "25000: D: 0.046048201620578766/0.27169665694236755 G: 1.1412861347198486 (Real: [3.9450775325298308, 1.2850648568548644], Fake: [4.8238542914390568, 1.093329721625997]) \n",
      "25200: D: 0.11421568691730499/0.110244981944561 G: 7.076096534729004 (Real: [3.9707006907463072, 1.2576149399429444], Fake: [5.044382600784302, 1.6456209918055456]) \n",
      "25400: D: 0.004191887099295855/0.01425089593976736 G: 4.015843868255615 (Real: [4.2159339296072718, 1.3259387362601329], Fake: [5.0247163224220275, 1.1472811058646335]) \n",
      "25600: D: 2.704078435897827/0.05746084451675415 G: 0.9536255598068237 (Real: [4.1439102494716646, 1.1631299583141981], Fake: [4.4511904025077822, 1.4080915840642505]) \n",
      "25800: D: 0.9379870295524597/0.7432636022567749 G: 0.03893222659826279 (Real: [4.0591919809579853, 1.2376610741173344], Fake: [3.6439341878890992, 0.98452371621478463]) \n",
      "26000: D: 0.384073942899704/1.4127681255340576 G: 0.6638132929801941 (Real: [3.9962968707084654, 1.1755286642233602], Fake: [3.6179152369499206, 1.2924347081657808]) \n",
      "26200: D: 0.5377306938171387/0.22550685703754425 G: 0.9358223676681519 (Real: [4.0557784575223925, 1.253274392280378], Fake: [5.4843526220321657, 1.4743471898773781]) \n",
      "26400: D: 0.02092708647251129/0.0448111966252327 G: 1.4024378061294556 (Real: [3.9939602249860764, 1.2817573221738536], Fake: [6.5263891029357914, 1.5468911903385625]) \n",
      "26600: D: 0.0601867251098156/0.003830854780972004 G: 6.055424213409424 (Real: [4.2646825945377351, 1.1737969544982401], Fake: [7.4663855075836185, 1.7115616401939713]) \n",
      "26800: D: 0.06024268642067909/0.42839762568473816 G: 1.8073019981384277 (Real: [4.0707507103681566, 1.3241638544422116], Fake: [7.724091267585754, 1.89184191735341]) \n",
      "27000: D: 0.05486913397908211/7.551573071395978e-05 G: 8.116446495056152 (Real: [3.9963647997379304, 1.1561023016839271], Fake: [7.6704958343505858, 2.0566920846379069]) \n",
      "27200: D: 0.012376527301967144/0.009759105741977692 G: 4.483093738555908 (Real: [4.2318062162399288, 1.2798928337201505], Fake: [8.0083650922775274, 1.4208734299007493]) \n",
      "27400: D: 0.0015481170266866684/0.0018895295215770602 G: 8.311905860900879 (Real: [3.9006900918483733, 1.1815767689384296], Fake: [8.0912236356735221, 1.4977729540276952]) \n",
      "27600: D: 0.010723965242505074/0.001465199631638825 G: 7.955950736999512 (Real: [4.1616671824455258, 1.2827768389877501], Fake: [8.7141226196289061, 1.4988283810471301]) \n",
      "27800: D: 1.358994995825924e-05/0.00044427657849155366 G: 7.682705402374268 (Real: [3.9259475921839475, 1.3845605086387527], Fake: [9.1016003942489618, 1.6320261884382155]) \n",
      "28000: D: 1.7285496141994372e-05/1.0253126674797386e-05 G: 7.453917503356934 (Real: [3.9553819361329077, 1.3096972209035258], Fake: [9.9009511327743525, 1.5915941181989433]) \n",
      "28200: D: 0.00021501706214621663/0.0001966334239114076 G: 10.609885215759277 (Real: [4.0642582058906553, 1.1841341062990467], Fake: [10.299726104736328, 1.7426952216029323]) \n",
      "28400: D: 0.0041008517146110535/2.0868745195912197e-05 G: 11.713861465454102 (Real: [4.2621503871679307, 1.245169931530383], Fake: [11.175182886123658, 1.7572987327997156]) \n",
      "28600: D: 9.876977128442377e-05/1.4734606338606682e-05 G: 16.34547233581543 (Real: [4.0398822954297069, 1.3699930685560702], Fake: [10.994895515441895, 1.8961721020075291]) \n",
      "28800: D: 0.004224568605422974/7.763070470900857e-07 G: 13.373473167419434 (Real: [4.034775209724903, 1.225313831908724], Fake: [10.487495331764221, 2.6456491183280098]) \n",
      "29000: D: 0.003533040639013052/1.8611479390528984e-05 G: 13.965729713439941 (Real: [4.1238148355484006, 1.2384558048609497], Fake: [10.862395095825196, 2.5926475295435756]) \n",
      "29200: D: 2.75973306997912e-05/6.320448301266879e-05 G: 10.975943565368652 (Real: [3.8782375234365465, 1.31046820213479], Fake: [10.733885855674744, 1.64540124150015]) \n",
      "29400: D: 5.793739182990976e-05/0.0002775181201286614 G: 11.636502265930176 (Real: [3.852319520711899, 1.1718524944791755], Fake: [10.689629974365234, 1.6264281912475054]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29600: D: 0.0010859303874894977/0.0009414429077878594 G: 10.873520851135254 (Real: [3.7867905431985855, 1.3014709660666599], Fake: [11.122827396392822, 1.5762867256918673]) \n",
      "29800: D: 4.202215495752171e-05/9.479149554181276e-08 G: 15.285253524780273 (Real: [4.0204957526922227, 1.3140525536356058], Fake: [13.194394207000732, 1.881389211628145]) \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
